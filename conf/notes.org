* Day one
** Keynote - Whither Web Programming?

   Gilad Bracha - coauthor Java 8 language spec

*** Strengths

    * Always available
      * ??
      * Offline can be flakey slow
      * Storage isn't always available
    * Hard to implement new languages
    * Issues (JS)
      * Integers not available
      * Concurrency
      * Privacy
      * Stack access
    * Dart
      * Try Dart online
        * Has to compile the program
      * But can make it faster by using incremental compilation [[http://gilad.try-dart-lang.appspot.com/][here]]
    * The Dart book
      * Isn't ready yet, because the reflection API isn't yet out.
      * The reflection API isn't read because the dart2js output is too
        large.
      * It's hard to know what you're going to call if you allow
        reflection.
      * In other languages you don't have to worry about keeping
        programs under 200kb.
    * Other
      * [[http://elm-lang.org/][Elm]]
        * A functional language for web UIs
        * Runs on the web with live environment
      * Leisure
        * presentation manager with built in functional lazy language

** Scaling Foursquare - From checkins to recommendations

   Jon Hoffman

   Foursquare have moved from just check-ins and have turned into a
   recommendation engine. There are 160 employees, 90 of which are
   engineers.

*** Data storage

    * Started with MySQL in 2009, but pretty quickly moved to Postgres.
    * Memcache in front of SQL engine.
    * By the time they had 1e6 users they had to split the DB
      * Joins in app code
      * Not enough RAM for indexes
    * Sharding
    * Consider Mongo, Cassandra, HBase
    * Mongo
      * They hoped that features would be developed just in time.
      * Gamble, but it worked.
      * 2010-2011 migration from Postgres to Mongo.
        * Custom code
      * Now 15 mongo clusters, 600 nodes
      * 1e6 million queries per second
    * Memcache
    * Elastic search
    * Readonly KV store
      * HFile service
      * Hadoop -> HFile -> App servers
      * Use Zookeeper for datatype to machine mapping
    * Zookeeper is the 'indispensable glue that holds everything
      together at Foursquare
    * Cachine service
      * Tail Mono oplog, put interesting events into Kafka, then info
        Redis cache.

*** Application complexity

    * Scala, Lift
    * Monolithic code base
      * Deploy everything all the time
      * Compile everything all the time
    * Move to SOA
      * Split into offline, API, Website
      * Looked at Finagle from Twitter
    * Trace requests by sending correlatoin ID from caller to callee.
    * Exception aggregation
    * ZooKeeper for host names
    * Circuit breaker
      * Loosely based on Hystrix from Netflix

** Facebook React

   * Fron Instagram
   * Build a virtual immutable DOM.
   * Throw away and rerender whenever things change.
   * Embded XML in the JS, there's a precompilation phase.
   * Reconcile
     * Figure out how to change the virtual DOM to match the immutable
       structure
     * Guarantee that the virtual DOM and the browser DOM will always
       match. Therefore, if youc create an input field with nothing in
       it, you won't be able to type in it.

** Devops practices to create flow - Jez Humble

   * [[http://www.slideshare.net/jezhumble/devops-culture-and-practices-to-create-flow][Slideshare]]

   * Where's the production line?
     * Commit which is the start on the production line
   * Kanban
   * Toyota made looms
     * Actually called Toyoda
     * The breakthrough loom automatically stopped when there was a problem
       * There was no way to make a defective product
   * Automation + People = autonomation
   * [[http://www.thisamericanlife.org/radio-archives/episode/403/nummi][This American Life NUMMI]]
     * GM plant with workforce that were demotivated
     * GM, Toyota joint venture
     * GM were going to fire everyone
     * Toyota rehired the 'worst workforce' and made them how to make
       high quality products
       * Cars never come off of the line in a broken state
       * Workers have the ability to stop the line and figure out what's wrong.
       * By giving workers control they were able to make the factory
         the best of GM
     * [[http://www.jamesshore.com/Blog/Continuous-Integration-on-a-Dollar-a-Day.html][James Shaw: CI on a dollar a day]]
       * Test, build locally
       * Take lock object
       * Check in
       * Build on other machine
         * If it fails, take the code out
   * Does CI scale?
     * Yes, better than feature branches. Work from master.
   * Validate before production
     * People might be needed
   * HP Laserjet
     * 5% time spent innovating, so need to change
     * Decided to rewrite
       * Consider [[http://martinfowler.com/bliki/StranglerApplication.html][strangler pattern]] instead of rewriting
     * All printers used to have different binaries. Change so that
       there is one binary.
     * Director of engineering - fix by walking and talking. "Why is the
       build breaking?"
     * Build pipeline
       * Levels of builds: 1, 2, 3, 4
       * 1 is basic tests
       * 2 is simulator
       * 3 firmware on logic boards
       * 30k hours of tests that run on a grid over night
       * Move the tests between levels. If a test at level one passes a
         lot, move it down. If a test at L4 fails a lot, move it up.
     * Get to the point where you get things done when you say that it's
       going to be done.
     * [[http://www.amazon.com/Practical-Approach-Large-Scale-Agile-Development/dp/0321821726][A Practical Approach to Large-Scale Agile Development]]
     * [[http://www.amazon.com/The-Corporate-Culture-Survival-Guide/dp/0470293713][A Corporate Culture Survival Guide]]
     * [[http://puppetlabs.com/sites/default/files/2014-state-of-devops-report.pdf][2014 State of Devops Report]]
     * High trust
       * Measure culture
         * Ron Westrum
     * What Toyota is doing at any one time isn't a best practice and
       you can't copy and paste it from one org to another. Toyota
       solves their current problems.
     * Let workers try things out - tell them where you want to get to,
       not how to get there. "What are we trying to achieve, where are
       we now, what's the next step?"
     * [[http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1765804/pdf/v013p0ii22.pdf][A typology of organisational cultures]]

** Big Data in Capital Markets

   * What is big data? In this presentation it's an umbrella term, for
     techniques, tools etc.
   * The Vs: Volume, Variety, Veracity, Velocity
   * Look at the fundamentals, not just copy 'internet firms'
   * Patterns
     * Hadoop as ETL
       * 70% of Hadoop deployments in finance are for ETL
     * Hadoop as BI
       * Hive, PIG
       * Impala
     * Multiasset datastore
     * Big data governance
   * Anti-patterns
     * Fine grained jobs - interdependency pain
   * Data
     * You can get an EC2 instance with 250GB of memory, so you only
       need four machines to handle 1TB. This isn't a massive change
       from what you're used to. If you want to keep things in memory
       and you have > 1PB you have to think harder.
     * All of flickr is 2PB.
     * Semi structured data
       * How much structure do you need?
       * Even if you have structured data, what happens if you have more
         than one set of data, each with a different structure?
       * NoSQL makes sense for rapid analysis
       * 99% of processing on unstructured data is to derive structure
         from it.
       * Moving data around is slow
     * Latency v througput
       * 1s to do something on one machine, 1s to do 10 things on 10
         machines *but* it still takes a second. You've increased
         throughput but the latency is the same.

*** Case studies

**** Hadoop archive

     Replace tape archive with HDFS. Tapes fail.

**** Client review

     Pull in information from one 'big data' repository for clients when
     they're 'on boarded'.

** Design and Evolution of Chartbeat's Architecture

   Wes Chow

   * Chartbeat has three products: Everyone, Publishers, Advertisers.
   * They measure engagement with sites: reading and writing. If the
     user is the moving the mouse or scrolling around then they're
     considered to be reading.
   * Chartbeat creates metrics that measure engagement.
   * Data is stored only with first party cookies (so they can't tell if
     you're the same user on a different site).
   * Data set using img tags

*** Memoryfly

    * A C++ in memory data store that they've written.
    * Can handle 200k pings per second.

*** Chartbeat architecture

    * Ping goes to Chartbeat.
    * There's a routing layer that chooses which shart to send data to
      based on the customer name.
    * They're running a custom NGinx server with embedded Lua.
    * They're using Lua because it's easy to embed in C and easy to
      write in.
    * They wrote Memoryfly before Storm came out

*** How to create a historical chart


          .            .....
          .      .......
          .     .
          .   ..
          ....
          ...................

    * Take snapshots periodically.
    * API servers send messages to async workers that write to Mongo
      replicas.
    * The API servers can then query the Mongo replicas.

*** What about really big cutomers?
    * Split the customer over more than one server
    * Data is split based on a view key hash.
    * Interesting problem: can't assume that the top 10 page overall is
      in the top 10 for any of the separate servers.

*** How to measure loyalty?
    * If you only measure visitors in aggregate it's impossible to tell
      if users return to the site. To find out if a user returns you
      have to sample all visitors. Depending on the size of the customer
      the percentage of people that are sampled varies between 1 and 100
      per cent.
    * Lua embedded in Nginx decides which traffic should be sampled.
    * Raw data is sent to S3, then EMR processes it and stores the
      results in Redshift.
    * Uses RabbitMQ for messaging

*** Lessons
    * Performance - it takes ~3ms for a random disk read with rotational
      disks.
    * Every five minutes they add a new lne to MongoDB. To get all
      customer data for a 24h period if the data is stored in a naive
      way the read head has to skip to every record.
    * If the data is sorted by customer instead then the query can do
      sequential reads.

** Facebook Apollo: Strong Consistency at Scale

*** Consistency
    * There's been innovation in weak consistency, but not much in
      strong systems.
    * AP is popular, see Cassandra and Dynamo
    * Facebook prefers CP

*** Replication

    * Sharded data @ one location
    * Slaves push data to other locations so other people can read them
    * Read after write
    * Sticky master (except after failure)
    * FB like to
      * have atomic updats
      * not lose writes
    * In a data centre you're likely to see whole rack failures (eg
      switch breaks).
    * AP style systems are cool, but you can use them to create CP style
      building blocks.

*** Apollo

    * C++11 with Thrift 2
    * Paxos
    * In the same way that HBase is build on top of HDFS, Apollo is
      built on top of a shared quorum.
    * The shart has
      * Consensus protocol build with Raft
      * Storage with RocksDB, MySQL
      * User storage CRDT
      * Use code execution

** Keynote: Engineering Velocity at Nefflix
   * Netflix wants to increase engineering speed.
   * They're aware that the rate of change is inversely proportional to
     the availability of the system.
   * What can they do to increase the availability too?
   * Engineers have freedom and responsibility
     * Example: engineer wanted to bring in Python. That was freedom. He
       also had the responsibility to write support for the language too.
   * Managers build context, they don't control.
     * Hire talented people and then get out of the way

*** Freedom
    * Built predictive autoscale because ASGs aren't predictive.
    * Predictive version can fall back to regular ASG behaviour if it
      doesn't correctly predict the load.
    * Netflix support multiple paths of exploration.
      * The tooling team hadn't finished working on the deployment
        tools, when another team needed to deploy. The other team wrote
        their own deployment software, and then the tool team could
        learn more about what works and what doesn't.

** Mike Feathers - If we took Conway's Law Seriously

   * Conway's law: System design will mirror the communication structure
     of the organisation that produced it
   * You do want boundaries in software. Put the authors of different
     sides of the boundary on different teams.
   * Active management - choose to use Conway's law to create
     differences in software
     * Split the team
     * Merge teams (how often does this happen?)
   * How do you maintain core knowledge yet still allow people to move
     around?
   * Monitor cruft. If people avoid working on bits of the software
     that's something that you need to know about.
   * Open for extension, closed for modification
     * Engineering principle
     * Monitor the code repositor for this

*** Turnover

    * High in the IT industry. Does the code turnover as much?
    * Code stays around longer than people. Ditch software and rewrite
      it more often. The team is not the codebase

*** Biology and software

    * There are similarities between biology and software.
    * As a species we survive because individuals die.
    * See the strangler pattern for replacing bits of software.
    * Book: Peter Provost - The Butterfly Effect
      * FxCop was created by MS to inrease the quality of code. It was
        meant to run every time you check software in to VCS and not let
        you check in if there is a problem with the code
        quality. Unfortunately a side effect is that people stopped
        checking in so often. It was a little change that affected
        quality in the wrong direction.
    * Practice large scale refactoring.

** Eric Evans - Strategic Design: Embrace Imperfection

   * You need to be able to make broad, true assertions about your software.
   * A bounded context is a part of a system when the assertion holds.
   * A team must agree on the meanings of the assertions.
   * Multiple different models are both desirable and inevitable.
     Two teams working on the same problem will have different
     models. The coordination overhead required to stop this is
     prohibitive - either have one team or allow the different models to
     form.
   * An example of good architecutre is Netflix's microservice
     architecture.
     * Each service is its own bounded context, and will nec. have it's
       own level of quality.
     * The acknowledge imperfection. See for example Chaos Monkey.
   * SOA allows us to define boundaries, but it's not required.
     * Example of something not to do - write services that share a DB.
   * Microservices talk to each other. The boundary that we've created
     allows us to dfeine a language to describe the service.
     You want different languages for different things. Be concious o
     fthe language and allow nouns to have different meanings in
     different places.

*** REST (Ken Webber)
    * Embrace imperfection. Don't try to implement the ideal. Parts of
      the web are actively trying to harm us, and yet it still works.
    * The big-ball-of-mud can be refactored to be good, but not everyone
      can do it.
    * If you want to get away from the BBOM then consider the legacy
      escape pattern
      * Add an anti-corruption layer

*** Accidental boundaries
    * We can accidentally create boundaries without realising. For
      example the trendy new language: people are attracted to the new
      language and it keeps the "riff-raff" out.
    * Eventually everyone will have to learn Scala, and therefore Scala
      projects will stop being so successful.
    * Consider Clojure as your next language.

*** Teams

    * Teams can change faster than software. Reorgs assign new teams to
      slices of contexts, but the software still represents the old org
      structure. Perhaps rewrite the code to match the new org structure.
